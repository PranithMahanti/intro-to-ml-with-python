# Chapter 2 - Supervised Learning
- Any intuition derived from datasets with few features (also called
low-dimensional datasets) might not hold in datasets with many features (high-
dimensional datasets)

## KNN Regressor
### R^2 Score
We can also evaluate the model using the score method, which for regressors returns
the R2 score. The R2 score, also known as the coefficient of determination, is a meas‐
ure of goodness of a prediction for a regression model, and yields a score between 0
and 1. A value of 1 corresponds to a perfect prediction, and a value of 0 corresponds
to a constant model that just predicts the mean of the training set responses, y_train:

### Advantages & Disadvantages of KNN prediction models
- One of the strengths of k-NN is that the model is very easy to understand, and often
gives reasonable performance without a lot of adjustments. 
- Using this algorithm is a good baseline method to try before considering more advanced techniques. 
- Building the nearest neighbors model is usually very fast, but when your training set is very
large (either in number of features or in number of samples) prediction can be slow.
- When using the k-NN algorithm, it’s important to preprocess your data.
- This approach often does not perform well on datasets with many features
(hundreds or more), and it does particularly badly with datasets where most features
are 0 most of the time (so-called sparse datasets).


